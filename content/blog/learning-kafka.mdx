---
title: "Understanding Kafka with Golang and Docker"
description: "A comprehensive guide on how to implement Apache Kafka using Golang and Docker, showcasing a simple order processing system."
tags: ["kafka", "golang", "docker", "microservices"]
date: "2024-10-03"
---

## Introduction

Apache Kafka is a powerful distributed event streaming platform used for building real-time data pipelines and streaming applications. This article explores how to implement Kafka in a Golang application using Docker to manage the required components efficiently.

## Architecture

The order processing system consists of three main components:

1. **Order Service**: Responsible for placing orders and publishing them to Kafka.
2. **Order Processor**: Consumes orders from Kafka, processes them, and triggers notifications.
3. **Email Service**: Sends confirmation emails to customers once their orders are processed.

## Features

- Kafka-based order processing system
- Order scheduling and processing
- Email notification upon order completion

## Setup

### Prerequisites

- **Docker**: Ensure Docker is installed and running on your machine.
- **Go**: Install Go programming language.

### Docker Compose

To manage the components, we will use Docker Compose. Create a `docker-compose.yml` file with the following content:

```yaml
version: '3.8'

services:
  kafka:
    image: docker.io/bitnami/kafka:3.6
    ports:
      - "9092:9092"
    volumes:
      - "kafka_data:/bitnami"
    environment:
      # KRaft settings
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      # Listeners
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
    networks:
      - my-network

  email-service:
    build:
      context: ./email-service
    restart: always
    container_name: email-service
    environment:
      - EMAIL_USER=your_email@example.com
      - EMAIL_PASSWORD=your_email_password
      - KAFKA_BROKER=kafka:9092
    depends_on:
      - kafka
    networks:
      - my-network

  order-processor:
    build:
      context: ./order-processor
    restart: always
    container_name: order-processor
    environment:
      - KAFKA_BROKER=kafka:9092
    depends_on:
      - kafka
    networks:
      - my-network

  order-service:
    build:
      context: ./order-service
    restart: always
    container_name: order-service
    ports:
      - "5000:5000"
    environment:
      - KAFKA_BROKER=kafka:9092
    depends_on:
      - kafka
    networks:
      - my-network

volumes:
  kafka_data:
    driver: local

networks:
  my-network:
    driver: bridge
```

## 3. Implementing the Golang Services
Now, let's implement the order-service and email-service using Golang. These services will interact with the Kafka server, one for publishing orders and the other for processing them.

#### 3.1 Order Service (Producer)
The order-service will handle placing orders and publishing them to the Kafka server.

```go
package main

import (
	"encoding/json"
	"log"
	"net/http"
	"time"

	"github.com/IBM/sarama"
)

type Order struct {
	ID     int    `json:"id"`
	Status string `json:"status"`
}

var kafkaProducer sarama.SyncProducer

func main() {
	setupKafkaProducer()

	http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
		w.WriteHeader(http.StatusOK)
		w.Write([]byte("Order Service"))
	})
	http.HandleFunc("/placeOrder", placeOrderHandler)
	// go scheduleCheckOrderStatus()

	log.Fatal(http.ListenAndServe(":5000", nil))
}

func setupKafkaProducer() {
	config := sarama.NewConfig()
	config.Producer.RequiredAcks = sarama.WaitForAll
	config.Producer.Retry.Max = 5
	config.Producer.Return.Successes = true

	producer, err := sarama.NewSyncProducer([]string{"kafka:9092"}, config)
	if err != nil {
		log.Fatal("Error creating Kafka producer:", err)
	}

	kafkaProducer = producer
	log.Println("Kafka producer connected successfully")
}

func placeOrderHandler(w http.ResponseWriter, r *http.Request) {
	var order Order
	err := json.NewDecoder(r.Body).Decode(&order)
	if err != nil {
		http.Error(w, err.Error(), http.StatusBadRequest)
		return
	}

	publishOrderToKafka(order)

	w.WriteHeader(http.StatusOK)

	w.Write([]byte("Order placed successfully"))
}

func publishOrderToKafka(order Order) {
	message, err := json.Marshal(order)
	if err != nil {
		log.Println("Error marshaling order:", err)
		return
	}

	_, _, err = kafkaProducer.SendMessage(&sarama.ProducerMessage{
		Topic: "orders",
		Value: sarama.StringEncoder(message),
	})
	if err != nil {
		log.Println("Error sending message to Kafka:", err)
	}
}

func scheduleCheckOrderStatus() {
	ticker := time.NewTicker(5 * time.Minute)

	for range ticker.C {
		processedOrder := Order{ID: 1, Status: "processed"}
		publishOrderToKafka(processedOrder)
	}
}
```



```dockerfile
FROM golang:1.21-alpine

COPY . /app

WORKDIR /app

RUN go mod download

RUN go build -o main .

CMD ["./main"] 
```

####  3.2 Order Processing Service (Consumer)
This service listens for order events from Kafka, processes the order, and updates its status.

```go
package main

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"os"
	"os/signal"
	"sync"
	"syscall"
	"time"

	"github.com/IBM/sarama"
)

type Order struct {
	ID     int    `json:"id"`
	Status string `json:"status"`
}

func main() {
	setupKafkaConsumer()
}

var wg sync.WaitGroup

func setupKafkaConsumer() {
	config := sarama.NewConfig()
	config.Consumer.Offsets.Initial = sarama.OffsetOldest

	consumer, err := sarama.NewConsumerGroup([]string{"kafka:9092"}, "my-group", config)
	if err != nil {
		log.Fatal(err)
	}
	defer consumer.Close()

	sigterm := make(chan os.Signal, 1)
	signal.Notify(sigterm, syscall.SIGINT, syscall.SIGTERM)

	// Create a channel to signal when the consumer is closed
	closedCh := make(chan struct{})

	go func() {
		defer wg.Done()
		for {
			err := consumer.Consume(context.Background(), []string{"orders"}, &orderConsumer{closedCh: closedCh})
			if err != nil {
				log.Println("Error from consumer:", err)
				// Check for errors and try to recover
				recoverConsumer(&consumer, closedCh)
			}
		}
	}()

	log.Println("Kafka consumer is now consuming messages from the 'orders' topic")

	// Wait for signals
	select {
	case <-sigterm:
		log.Println("Interrupt is detected")
	case <-closedCh:
		log.Println("Consumer closed")
	}

	// Wait for the consumer goroutine to finish
	wg.Wait()
}

func recoverConsumer(consumer *sarama.ConsumerGroup, closedCh chan struct{}) {
	log.Println("Attempting to recover the consumer...")
	time.Sleep(5 * time.Second) // Wait for a while before retrying

	// Check if the consumer is still open
	if (*consumer).Close() != nil {
		log.Println("Consumer is already closed. Cannot recover.")
		return
	}

	// Create a new consumer and replace the existing one
	newConsumer, err := sarama.NewConsumerGroup([]string{"kafka:9092"}, "order-consumer-group", sarama.NewConfig())
	if err != nil {
		log.Println("Error creating a new consumer:", err)
		return
	}

	// Replace the existing consumer with the new one
	(*consumer).Close()
	consumer = &newConsumer

	log.Println("Consumer recovered successfully.")
}

type orderConsumer struct {
	closedCh chan struct{}
}

func (oc *orderConsumer) Setup(session sarama.ConsumerGroupSession) error {
	return nil
}

func (oc *orderConsumer) Cleanup(session sarama.ConsumerGroupSession) error {
	return nil
}

func (oc *orderConsumer) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error {
	for msg := range claim.Messages() {
		var order Order
		err := json.Unmarshal(msg.Value, &order)
		if err != nil {
			log.Println("Error unmarshaling order:", err)
			continue
		}

		if order.Status == "processed" {
			processOrder(order)
		}

		session.MarkMessage(msg, "")
	}

	// Notify that the consumer has finished consuming
	oc.closedCh <- struct{}{}

	return nil
}

func processOrder(order Order) {
	fmt.Println("Processing order: ", order.Status)
	log.Printf("Processing Order ID: %d, Status: %s\n", order.ID, order.Status)
}
```

```dockerfile
FROM golang:1.21-alpine

COPY . /app

WORKDIR /app

RUN go mod download

RUN go build -o main .

CMD ["./main"] 
```

#### 3.3 Email Service
This service listens for processed order events and sends an email to the customer.

```go
package main

import (
	"bytes"
	"encoding/json"
	"html/template"
	"log"
	"net/smtp"

	"github.com/IBM/sarama"
)

type Order struct {
	ID     int    `json:"id"`
	Status string `json:"status"`
}

func main() {
	setupKafkaConsumer()
}

func setupKafkaConsumer() {
	config := sarama.NewConfig()
	consumer, err := sarama.NewConsumer([]string{"kafka:9092"}, config)
	if err != nil {
		log.Fatal("Error creating Kafka consumer:", err)
	}
	defer consumer.Close()

	partitionConsumer, err := consumer.ConsumePartition("orders", 0, sarama.OffsetOldest)
	if err != nil {
		log.Fatal("Error consuming Kafka partition:", err)
	}

	for {
		select {
		case msg := <-partitionConsumer.Messages():
			var order Order
			err := json.Unmarshal(msg.Value, &order)
			if err != nil {
				log.Println("Error unmarshaling order:", err)
				continue
			}

			sendEmail(order)
		}
	}
}

func sendEmail(order Order) {
	to := "customer@example.com"
	subject := "Order Processed"
	emailBody := createEmailBody(order)

	// Email configuration
	emailUser := "your_email@example.com"
	emailPassword := "your_password"
	emailServer := "smtp.example.com"
	emailPort := "587"

	// Send the email
	auth := smtp.PlainAuth("", emailUser, emailPassword, emailServer)
	err := smtp.SendMail(emailServer+":"+emailPort, auth, emailUser, []string{to}, []byte(emailBody))
	if err != nil {
		log.Println("Error sending email:", err)
	} else {
		log.Println("Email sent successfully")
	}
}

func createEmailBody(order Order) string {
	templateStr := `
	Subject: {{.Subject}}
	MIME-version: 1.0;
	Content-Type: text/html; charset="UTF-8";

	<!DOCTYPE html>
	<html lang="en">
	<head>
		<meta charset="UTF-8">
		<title>Order Confirmation</title>
	</head>
	<body>
		<h1>Order Processed</h1>
		<p>Your order with ID: <strong>{{.ID}}</strong> has been successfully processed.</p>
	</body>
	</html>`

	tmpl, err := template.New("email").Parse(templateStr)
	if err != nil {
		log.Fatal("Error parsing email template:", err)
	}

	var body bytes.Buffer
	err = tmpl.Execute(&body, map[string]interface{}{"Subject": "Order Processed", "ID": order.ID})
	if err != nil {
		log.Fatal("Error executing email template:", err)
	}

	return body.String()
}
```

```dockerfile
FROM golang:1.21-alpine

COPY . /app

WORKDIR /app

RUN go mod download

RUN go build -o main .

CMD ["./main"] 
```

## 4. Running Everything Together

Once the services are set up, follow these steps to run everything:

1. Create the `docker-compose.yml` file as defined earlier.

2. Place the code for `order-service`, `order-processing-service`, and `email-service` in separate directories (e.g., `./order-service`, `./order-processing-service`, and `./email-service`).

3. Build and start the services using Docker Compose: 
	```bash
	docker-compose up --build
	```

This command will build your Docker images and start all the services: the Kafka server, `order-service`, `order-processing-service`, and `email-service`. The `order-service` will publish order messages, which will be processed by the `order-processing-service`, and confirmation emails will be sent by the `email-service`.


## 5.Visualize Flow

![Sequence Diagram](/posts/kafka.png)

### Test Curl

```bash
curl -X POST -H "Content-Type: application/json
" -d '{"id": 235, "status": "processed"}' http://localhost:5000/placeOrder
```




## Conclusion
This article provided a comprehensive guide on implementing an order processing system using `Kafka` with `Golang` and `Docker`. By leveraging Kafka's messaging capabilities, you can build a robust and scalable microservices architecture. Experiment with the code and try adding additional features like error handling, logging, or more complex workflows!
